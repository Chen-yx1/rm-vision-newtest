#!/usr/bin/env python3
"""
RoboMaster ç›¸æœºæ ‡å®šè„šæœ¬
ç”¨äºç”Ÿæˆæ£‹ç›˜æ ¼æ ‡å®šå›¾åƒæˆ–æ‰§è¡Œç›¸æœºæ ‡å®š

ä½¿ç”¨æ–¹æ³•ï¼š
1. ç”Ÿæˆæµ‹è¯•å›¾åƒï¼špython calibrate_camera.py generate
2. æ‰§è¡Œç›¸æœºæ ‡å®šï¼špython calibrate_camera.py
"""

import cv2
import numpy as np
import os
import sys
import glob
import argparse
from datetime import datetime

def print_banner():
    """æ‰“å°ç¨‹åºæ¨ªå¹…"""
    print("=" * 60)
    print("RoboMaster ç›¸æœºæ ‡å®šå·¥å…·")
    print("=" * 60)

def create_calibration_images(output_dir="calibration_images", num_images=20):
    """
    åˆ›å»ºè™šæ‹Ÿæ£‹ç›˜æ ¼æ ‡å®šå›¾åƒï¼ˆç”¨äºæµ‹è¯•ï¼‰
    
    å‚æ•°ï¼š
        output_dir: è¾“å‡ºç›®å½•
        num_images: ç”Ÿæˆçš„å›¾åƒæ•°é‡
    """
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)
        print(f"âœ… åˆ›å»ºç›®å½•: {output_dir}")
    
    # æ£‹ç›˜æ ¼å‚æ•°
    pattern_size = (9, 6)  # å†…è§’ç‚¹æ•°é‡ (åˆ—, è¡Œ)
    square_size = 25       # æ–¹æ ¼å¤§å°ï¼ˆæ¯«ç±³ï¼‰
    
    print(f"ğŸ“¸ ç”Ÿæˆ {num_images} å¼ æ£‹ç›˜æ ¼æ ‡å®šå›¾åƒ...")
    print(f"  æ£‹ç›˜æ ¼: {pattern_size[0]}x{pattern_size[1]} å†…è§’ç‚¹")
    print(f"  æ–¹æ ¼å¤§å°: {square_size}mm")
    
    for i in range(num_images):
        # åˆ›å»ºç™½è‰²èƒŒæ™¯å›¾åƒ
        img = np.ones((480, 640, 3), np.uint8) * 255
        
        # ç”Ÿæˆä¸–ç•Œåæ ‡ç³»ä¸­çš„è§’ç‚¹
        obj_points = np.zeros((pattern_size[0] * pattern_size[1], 3), np.float32)
        obj_points[:, :2] = np.mgrid[0:pattern_size[0], 0:pattern_size[1]].T.reshape(-1, 2)
        obj_points *= square_size
        
        # éšæœºæ—‹è½¬å’Œå¹³ç§»ï¼ˆæ¨¡æ‹Ÿä¸åŒè§’åº¦æ‹æ‘„ï¼‰
        rvec = np.random.rand(3, 1) * 0.8 - 0.4  # -0.4åˆ°0.4å¼§åº¦
        tvec = np.array([0, 0, 600 + np.random.rand() * 300], dtype=np.float32).reshape(3, 1)
        
        # è™šæ‹Ÿç›¸æœºå†…å‚
        camera_matrix = np.array([[800, 0, 320], [0, 800, 240], [0, 0, 1]], dtype=np.float32)
        dist_coeffs = np.zeros((5, 1), np.float32)
        
        # å°†3Dç‚¹æŠ•å½±åˆ°2Då›¾åƒå¹³é¢
        img_points, _ = cv2.projectPoints(obj_points, rvec, tvec, camera_matrix, dist_coeffs)
        
        # ç»˜åˆ¶æ£‹ç›˜æ ¼è§’ç‚¹
        for point in img_points.reshape(-1, 2):
            cv2.circle(img, tuple(point.astype(int)), 4, (0, 0, 0), -1)
        
        # ç»˜åˆ¶æ£‹ç›˜æ ¼çº¿
        points = img_points.reshape(pattern_size[1], pattern_size[0], 2)
        for row in range(pattern_size[1]):
            for col in range(pattern_size[0] - 1):
                pt1 = tuple(points[row, col].astype(int))
                pt2 = tuple(points[row, col + 1].astype(int))
                cv2.line(img, pt1, pt2, (0, 0, 0), 2)
        
        for col in range(pattern_size[0]):
            for row in range(pattern_size[1] - 1):
                pt1 = tuple(points[row, col].astype(int))
                pt2 = tuple(points[row + 1, col].astype(int))
                cv2.line(img, pt1, pt2, (0, 0, 0), 2)
        
        # æ·»åŠ å›¾åƒç¼–å·
        cv2.putText(img, f"Chessboard {i+1:03d}", (20, 30), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)
        
        # ä¿å­˜å›¾åƒ
        filename = os.path.join(output_dir, f"chessboard_{i+1:03d}.jpg")
        cv2.imwrite(filename, img)
        
        # æ˜¾ç¤ºè¿›åº¦
        if (i + 1) % 5 == 0:
            print(f"  å·²ç”Ÿæˆ {i+1}/{num_images} å¼ å›¾åƒ")
    
    print(f"âœ… æ ‡å®šå›¾åƒå·²ä¿å­˜åˆ°: {output_dir}/")
    print("âš ï¸  æ³¨æ„ï¼šè¿™äº›æ˜¯è™šæ‹Ÿå›¾åƒï¼Œä»…ç”¨äºæµ‹è¯•ã€‚")
    print("   è¯·ä½¿ç”¨çœŸå®ç›¸æœºæ‹æ‘„æ£‹ç›˜æ ¼è¿›è¡Œå®é™…æ ‡å®šã€‚")

def calibrate_camera(image_dir="calibration_images", pattern_size=(9,6), square_size=0.025):
    """
    æ‰§è¡Œç›¸æœºæ ‡å®š
    
    å‚æ•°ï¼š
        image_dir: æ ‡å®šå›¾åƒç›®å½•
        pattern_size: æ£‹ç›˜æ ¼å†…è§’ç‚¹æ•°é‡ (åˆ—, è¡Œ)
        square_size: æ£‹ç›˜æ ¼å®é™…å¤§å°ï¼ˆç±³ï¼‰
    """
    if not os.path.exists(image_dir):
        print(f"âŒ é”™è¯¯ï¼šç›®å½• '{image_dir}' ä¸å­˜åœ¨ï¼")
        print("è¯·å…ˆæ”¾ç½®æ ‡å®šå›¾åƒæˆ–è¿è¡Œ: python calibrate_camera.py generate")
        return False
    
    # æŸ¥æ‰¾æ‰€æœ‰å›¾åƒæ–‡ä»¶
    image_files = sorted(glob.glob(os.path.join(image_dir, "*.jpg")) + 
                        glob.glob(os.path.join(image_dir, "*.png")) +
                        glob.glob(os.path.join(image_dir, "*.jpeg")) +
                        glob.glob(os.path.join(image_dir, "*.bmp")))
    
    if len(image_files) == 0:
        print(f"âŒ é”™è¯¯ï¼šåœ¨ '{image_dir}' ä¸­æœªæ‰¾åˆ°å›¾åƒæ–‡ä»¶ï¼")
        print("æ”¯æŒçš„æ ¼å¼: .jpg, .png, .jpeg, .bmp")
        return False
    
    print(f"ğŸ“ æ‰¾åˆ° {len(image_files)} å¼ æ ‡å®šå›¾åƒ")
    
    # å‡†å¤‡æ ‡å®šæ•°æ®
    obj_points = []  # ä¸–ç•Œåæ ‡ç³»ä¸­çš„3Dç‚¹
    img_points = []  # å›¾åƒåæ ‡ç³»ä¸­çš„2Dç‚¹
    
    # ç”Ÿæˆä¸–ç•Œåæ ‡ç³»ä¸­çš„æ£‹ç›˜æ ¼è§’ç‚¹
    objp = np.zeros((pattern_size[0] * pattern_size[1], 3), np.float32)
    objp[:, :2] = np.mgrid[0:pattern_size[0], 0:pattern_size[1]].T.reshape(-1, 2)
    objp *= square_size
    
    print("ğŸ” å¼€å§‹æ£€æµ‹æ£‹ç›˜æ ¼è§’ç‚¹...")
    
    success_count = 0
    for i, filepath in enumerate(image_files):
        filename = os.path.basename(filepath)
        
        # è¯»å–å›¾åƒ
        img = cv2.imread(filepath)
        if img is None:
            print(f"  [{i+1:03d}] âŒ æ— æ³•è¯»å–: {filename}")
            continue
        
        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        
        # æŸ¥æ‰¾æ£‹ç›˜æ ¼è§’ç‚¹
        ret, corners = cv2.findChessboardCorners(gray, pattern_size, 
                                                 cv2.CALIB_CB_ADAPTIVE_THRESH + 
                                                 cv2.CALIB_CB_FAST_CHECK + 
                                                 cv2.CALIB_CB_NORMALIZE_IMAGE)
        
        if ret:
            # äºšåƒç´ ç²¾ç¡®åŒ–
            criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)
            corners_refined = cv2.cornerSubPix(gray, corners, (11, 11), (-1, -1), criteria)
            
            obj_points.append(objp)
            img_points.append(corners_refined)
            
            # æ˜¾ç¤ºæ£€æµ‹ç»“æœ
            img_display = img.copy()
            cv2.drawChessboardCorners(img_display, pattern_size, corners_refined, ret)
            
            # æ·»åŠ çŠ¶æ€ä¿¡æ¯
            cv2.putText(img_display, f"OK: {filename}", (10, 30), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)
            
            success_count += 1
            print(f"  [{i+1:03d}] âœ… æˆåŠŸ: {filename}")
        else:
            print(f"  [{i+1:03d}] âŒ å¤±è´¥: {filename} - æœªæ‰¾åˆ°æ£‹ç›˜æ ¼è§’ç‚¹")
    
    print(f"\nğŸ“Š è§’ç‚¹æ£€æµ‹ç»“æœ: {success_count}/{len(image_files)} å¼ å›¾åƒæˆåŠŸ")
    
    if success_count < 10:
        print(f"âŒ é”™è¯¯ï¼šè‡³å°‘éœ€è¦10å¼ æˆåŠŸå›¾åƒï¼Œå½“å‰åªæœ‰ {success_count} å¼ ")
        print("è¯·ç¡®ä¿:")
        print("  1. æ£‹ç›˜æ ¼å®Œæ•´å‡ºç°åœ¨å›¾åƒä¸­")
        print("  2. æ£‹ç›˜æ ¼æ–¹å‘å¤šæ ·ï¼ˆä¸åŒè§’åº¦å’Œè·ç¦»ï¼‰")
        print("  3. å›¾åƒæ¸…æ™°ä¸æ¨¡ç³Š")
        return False
    
    # è·å–å›¾åƒå°ºå¯¸
    img_sample = cv2.imread(image_files[0])
    h, w = img_sample.shape[:2]
    
    print("ğŸ¯ å¼€å§‹ç›¸æœºæ ‡å®š...")
    
    # æ‰§è¡Œæ ‡å®š
    ret, camera_matrix, dist_coeffs, rvecs, tvecs = cv2.calibrateCamera(
        obj_points, img_points, (w, h), None, None)
    
    # è®¡ç®—é‡æŠ•å½±è¯¯å·®
    mean_error = 0
    for i in range(len(obj_points)):
        imgpoints2, _ = cv2.projectPoints(obj_points[i], rvecs[i], tvecs[i], 
                                         camera_matrix, dist_coeffs)
        error = cv2.norm(img_points[i], imgpoints2, cv2.NORM_L2) / len(imgpoints2)
        mean_error += error
    
    mean_error /= len(obj_points)
    
    print("\n" + "=" * 60)
    print("ğŸ‰ ç›¸æœºæ ‡å®šå®Œæˆï¼")
    print("=" * 60)
    
    print(f"\nğŸ“ˆ æ ‡å®šè´¨é‡æŒ‡æ ‡:")
    print(f"  é‡æŠ•å½±è¯¯å·®: {mean_error:.6f}")
    print(f"  (è¯¯å·® < 0.5 è¡¨ç¤ºæ ‡å®šè´¨é‡è‰¯å¥½)")
    
    print(f"\nğŸ“· ç›¸æœºå†…å‚çŸ©é˜µ (K):")
    print(f"  fx = {camera_matrix[0,0]:.2f}  (ç„¦è·x)")
    print(f"  fy = {camera_matrix[1,1]:.2f}  (ç„¦è·y)")
    print(f"  cx = {camera_matrix[0,2]:.2f}  (ä¸»ç‚¹x)")
    print(f"  cy = {camera_matrix[1,2]:.2f}  (ä¸»ç‚¹y)")
    print(f"\n  [[{camera_matrix[0,0]:.2f}, {camera_matrix[0,1]:.2f}, {camera_matrix[0,2]:.2f}]")
    print(f"   [{camera_matrix[1,0]:.2f}, {camera_matrix[1,1]:.2f}, {camera_matrix[1,2]:.2f}]")
    print(f"   [{camera_matrix[2,0]:.2f}, {camera_matrix[2,1]:.2f}, {camera_matrix[2,2]:.2f}]]")
    
    print(f"\nğŸ”§ ç•¸å˜ç³»æ•° (D):")
    print(f"  k1 = {dist_coeffs[0,0]:.6f}")
    print(f"  k2 = {dist_coeffs[0,1]:.6f}")
    print(f"  p1 = {dist_coeffs[0,2]:.6f}")
    print(f"  p2 = {dist_coeffs[0,3]:.6f}")
    print(f"  k3 = {dist_coeffs[0,4]:.6f}" if len(dist_coeffs[0]) > 4 else "  k3 = 0.0")
    
    # ä¿å­˜æ ‡å®šç»“æœ
    save_file = "camera_calibration.yml"
    fs = cv2.FileStorage(save_file, cv2.FileStorage.WRITE)
    
    fs.write("calibration_date", datetime.now().strftime("%Y-%m-%d %H:%M:%S"))
    fs.write("image_width", w)
    fs.write("image_height", h)
    fs.write("camera_matrix", camera_matrix)
    fs.write("distortion_coefficients", dist_coeffs)
    fs.write("reprojection_error", mean_error)
    fs.write("successful_images", success_count)
    fs.write("total_images", len(image_files))
    
    fs.release()
    
    print(f"\nğŸ’¾ æ ‡å®šç»“æœå·²ä¿å­˜åˆ°: {save_file}")
    
    # æ˜¾ç¤ºå»ç•¸å˜æ•ˆæœ
    print("\nğŸ–¼ï¸  æ˜¾ç¤ºå»ç•¸å˜æ•ˆæœå¯¹æ¯”...")
    
    # è·å–æœ€ä¼˜æ–°ç›¸æœºçŸ©é˜µ
    new_camera_matrix, roi = cv2.getOptimalNewCameraMatrix(
        camera_matrix, dist_coeffs, (w, h), 1, (w, h))
    
    # åŠ è½½ç¬¬ä¸€å¼ æˆåŠŸæ ‡å®šçš„å›¾åƒ
    for filepath in image_files:
        img = cv2.imread(filepath)
        if img is not None:
            # å»ç•¸å˜
            dst = cv2.undistort(img, camera_matrix, dist_coeffs, None, new_camera_matrix)
            
            # è£å‰ªROIåŒºåŸŸ
            x, y, w2, h2 = roi
            dst_cropped = dst[y:y+h2, x:x+w2]
            
            # å¹¶æ’æ˜¾ç¤º
            comparison = np.hstack([img, dst, dst_cropped])
            
            # æ·»åŠ æ ‡ç­¾
            h_comparison, w_comparison = comparison.shape[:2]
            cv2.putText(comparison, "åŸå§‹å›¾åƒ", (10, 30), 
                       cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
            cv2.putText(comparison, "å»ç•¸å˜å›¾åƒ", (w + 10, 30), 
                       cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
            cv2.putText(comparison, "è£å‰ªåå›¾åƒ", (2*w + 10, 30), 
                       cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
            
            cv2.imshow("æ ‡å®šæ•ˆæœå¯¹æ¯” (æŒ‰ä»»æ„é”®ç»§ç»­)", comparison)
            cv2.waitKey(2000)
            break
    
    cv2.destroyAllWindows()
    
    print("\nâœ… ç›¸æœºæ ‡å®šæµç¨‹å®Œæˆï¼")
    print("ç°åœ¨å¯ä»¥è¿è¡Œä¸»ç¨‹åºå¹¶åŠ è½½æ ‡å®šå‚æ•°äº†ã€‚")
    print("ä½¿ç”¨æ–¹æ³•ï¼š")
    print("  1. è¿è¡Œä¸»ç¨‹åº: ./bin/rm_vision_newtest")
    print("  2. æŒ‰ 'l' é”®åŠ è½½æ ‡å®šå‚æ•°")
    print("  3. æŒ‰ '3' é”®æ˜¾ç¤º3Dåæ ‡")
    
    return True

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='RoboMaster ç›¸æœºæ ‡å®šå·¥å…·')
    parser.add_argument('command', nargs='?', default='calibrate',
                       help='å‘½ä»¤: generate (ç”Ÿæˆæµ‹è¯•å›¾åƒ) æˆ– calibrate (æ‰§è¡Œæ ‡å®š)')
    parser.add_argument('--dir', default='calibration_images',
                       help='æ ‡å®šå›¾åƒç›®å½• (é»˜è®¤: calibration_images)')
    parser.add_argument('--num', type=int, default=20,
                       help='ç”Ÿæˆæµ‹è¯•å›¾åƒçš„æ•°é‡ (é»˜è®¤: 20)')
    parser.add_argument('--pattern', default='9x6',
                       help='æ£‹ç›˜æ ¼å†…è§’ç‚¹æ•°é‡ (æ ¼å¼: åˆ—xè¡Œ, é»˜è®¤: 9x6)')
    parser.add_argument('--size', type=float, default=0.025,
                       help='æ£‹ç›˜æ ¼æ–¹æ ¼å®é™…å¤§å° (ç±³, é»˜è®¤: 0.025)')
    
    args = parser.parse_args()
    
    print_banner()
    
    # è§£ææ£‹ç›˜æ ¼å‚æ•°
    try:
        pattern_cols, pattern_rows = map(int, args.pattern.split('x'))
        pattern_size = (pattern_cols, pattern_rows)
    except:
        print(f"âŒ é”™è¯¯ï¼šæ£‹ç›˜æ ¼å‚æ•°æ ¼å¼æ— æ•ˆ '{args.pattern}'")
        print("æ­£ç¡®æ ¼å¼: åˆ—xè¡Œ (ä¾‹å¦‚: 9x6)")
        return
    
    if args.command.lower() == 'generate':
        print("ğŸ› ï¸  ç”Ÿæˆæ ‡å®šæµ‹è¯•å›¾åƒ...")
        create_calibration_images(args.dir, args.num)
    elif args.command.lower() == 'calibrate':
        print("ğŸ¯ æ‰§è¡Œç›¸æœºæ ‡å®š...")
        calibrate_camera(args.dir, pattern_size, args.size)
    else:
        print(f"âŒ é”™è¯¯ï¼šæœªçŸ¥å‘½ä»¤ '{args.command}'")
        print("å¯ç”¨å‘½ä»¤:")
        print("  generate - ç”Ÿæˆæµ‹è¯•æ ‡å®šå›¾åƒ")
        print("  calibrate - æ‰§è¡Œç›¸æœºæ ‡å®š")
        print("\nç¤ºä¾‹:")
        print("  python calibrate_camera.py generate")
        print("  python calibrate_camera.py calibrate")
        print("  python calibrate_camera.py calibrate --dir my_calib_images --pattern 8x6")

if __name__ == "__main__":
    main()